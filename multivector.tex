%
% Copyright © 2020 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\input{../latex/blogpost.tex}
\renewcommand{\basename}{multivector}
%\renewcommand{\dirname}{notes/phy1520/}
\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}

\input{../latex/peeter_prologue_print2.tex}

\usepackage{peeters_layout_exercise}
\usepackage{peeters_braket}
\usepackage{peeters_figures}
\usepackage{siunitx}
\usepackage{verbatim}
%\usepackage{mhchem} % \ce{}
%\usepackage{macros_bm} % \bcM
%\usepackage{macros_qed} % \qedmarker
%\usepackage{txfonts} % \ointclockwise

\beginArtNoToc

\generatetitle{Multivector}
%\chapter{Multivector}
%\label{chap:multivector}

\paragraph{Motivation.}
Many introductions to geometric algebra start by first introducing the dot product, then bivectors and the wedge product, and eventually define the product of two vectors as the synthetic sum of the dot and wedge
\begin{equation}\label{eqn:multivector:n}
\Bx \By = \Bx \cdot \By + \Bx \wedge \By.
\end{equation}
It takes a fair amount of work to do this well.  In the seminal work \citep{hestenes1999nfc} a few pages are taken for each of the dot and wedge products, showing the similarities and building up ideas, before introducing the geometric product in this fashion.  In \citep{dorst2007gac} the authors take a phenomenal five chapters to build up the context required to introduce the geometric product.  
I am not disparaging the authors for taking that long to build up the ideas, as their introduction of the subject is exceedingly clear and thorough, and they do a lot more than the minumum required to define the geometric product.

The strategy to introduce the geometric product as a sum of dot and wedge can result in considerable confusion, especially since the wedge product is often defined in terms of the geometric product
\begin{equation}\label{eqn:multivector:n}
\Bx \wedge \By = 
\inv{2} \lr{
\Bx \By - \By \Bx 
}.
\end{equation}
The whole subject can appear like a chicken and egg problem.  I personally found the subject very confusing initially, and had considerable difficulty understanding which of the many 
identities of geometric algebra were the most fundamental.  For this reason, I found the axiomatic approach of \citep{doran2003gap} very refreshing.  The cavaet with that work is that is is exceptionally terse, as they jammed a reformulation of most of physics using geometric algebra into that single book, and it would have been thousands of pages had they tried to make it readable by mere mortals.

When I wrote my own book on the subject, I had the intuition that the way to introduce the subject ought to be like the vector space in abstract linear algebra.  The construct of a vector space is a curious and indirect way to define a vector.  Vectors are not defined as entities, but simply as members of a vector space, a space that is required to have a set of properties.  I thought that the same approach would probably work with multivectors, which could be defined as members of a multivector space, a mathematical construction with a set of properties.  

I did try this approach, but was not fully satisfied with what I wrote.  I think that dissatisfaction was that I tried to define the multivector first, and introduced a whole set of 
prerequisite ideas (bivector, trivector, blade, k-vector, vector product, ...) to do so.
Looking back at this, I think that it shows some mathematical cowardness.  Had I taken the approach of the vector space fully to heart, the multivector could have been defined as a member of a multivector space, and all the other ideas follow from that.  In this article, I'm going to play with this approach anew, and see how it works out.
\paragraph{Vector space.}
Our starting point is the vector space, which is defined as

A vector space is a set \( V = \setlr{\Bx, \By, \Bz, \cdots} \), the elements of which are called vectors, which has an addition operation designated \( + \) and a scalar multiplication operation designated by juxtaposition, where the following axioms are satisfied
for all vectors \( \Bx, \By, \Bz \in V \) and scalars \( a, b \in \bbR \).

\begin{tabular}{|l|l|}
\hline
V is closed under addition & \( \Bx + \By \in V \)  \\ \hline
V is closed under scalar multiplication & \( a \Bx \in V \)  \\ \hline
Addition is associative & \( (\Bx + \By) + \Bz = \Bx + (\By + \Bz) \)  \\ \hline
Addition is commutative & \( \By + \Bx = \Bx + \By \)  \\ \hline
There exists a zero element \( \Bzero \in V \)  & \( \Bx + \Bzero = \Bx \)  \\ \hline
For any \( \Bx \in V \) there exists a negative additive inverse \( -\Bx \in V \) & \( \Bx + (-\Bx) = \Bzero \)  \\ \hline
Scalar multiplication is distributive  & \( a( \Bx + \By ) = a \Bx + a \By \), \( (a + b)\Bx = a \Bx + b\Bx \)  \\ \hline
Scalar multiplication is associative & \( (a b) \Bx = a ( b \Bx ) \)  \\ \hline
There exists a multiplicative identity & \( 1 \Bx = \Bx \) \\ \hline
\end{tabular}

%In geometric algebra, we require what can loosely be called a dot product.
%A dot product usually has the following characteristics
%
%- Symmetric : $ \Bx \cdot \By = \By \cdot \Bx $
%- Bilinear : $ (a \Bx + b \By) \cdot \Bz = a \Bx \cdot \Bz + b \By \cdot \Bz,\quad \Bx \cdot (a \By + b \Bz) = a \Bx \cdot \By + b \Bx \cdot \Bz $
%- Positive length : $ \Bx \cdot \Bx > 0, \Bx \ne 0 $
%
%, but the positive definite nature of that dot product is not required.
%
If a vector space \( V \) contains elements \( \Bx, \By \), we designate that dot product as \( \Bx \cdot \By \), and require

Symmetric : \( \Bx \cdot \By = \By \cdot \Bx \)

Bilinear : \( (a \Bx + b \By) \cdot \Bz = a \Bx \cdot \Bz + b \By \cdot \Bz,\quad \Bx \cdot (a \By + b \Bz) = a \Bx \cdot \By + b \Bx \cdot \Bz \)

Positive length : \( \Bx \cdot \Bx > 0, \Bx \ne 0 \)


Recall that a vector space with an associated dot product is called a dot product space.

Given a finite dimensional (dot-product) vector space \( V = \setlr{ \Bx, \By, \Bz, \cdots } \), with a dot product where the dot product of elements
, with a dot product \( \Bx \cdot \By \)
a multivector space generated by \( V \) is a set \( M = \setlr{ x, y, z, \cdots } \) of multivectors (sums of scalars, vectors, or products of vectors), where the following axioms are satisfied

Contraction : \( \Bx^2 = \Bx \cdot \Bx, \,\forall \Bx \in V \)

\( M \) is closed under addition : \( x + y \in M \)

\( M \) is closed under multiplication : \( x y \in M \)

Addition is associative : \( (x + y) + z = x + (y + z) \)

Addition is commutative : \( y + x = x + y \)

There exists a zero element \( 0 \in M \)  : \( x + 0 = x \)

For all \( x \in M \) there exists a negative additive inverse \( -x \in M \) : \( x + (-x) = 0 \)

Multiplication is distributive  : \( x( y + z ) = x y + x z \), \( (x + y)z = x z + y z \)

Multiplication is associative : \( (x y) z = x ( y z ) \)

There exists a multiplicative identity \( 1 \in M \) : \( 1 x = x \)

Clearly $\mathbb{R}$, using scalar multiplication as the dot product, is a multivector space.

It's possible to show that $\mathbb{R}^2$, $\mathbb{R}^3$, and other vector spaces (with the normal Euclidean dot product) also generate multivector spaces.  Both of these first require that we show that \( \Bx \By = - \By \Bx \), if \( \Bx \cdot \By = 0 \), that is, the products of perpendicular vectors, assumed to be members of  anticommute.

%}
\EndArticle
