%
% Copyright © 2022 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\input{../latex/blogpost.tex}
\renewcommand{\basename}{fsquared}
%\renewcommand{\dirname}{notes/phy1520/}
\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}

\input{../latex/peeter_prologue_print2.tex}

\usepackage{peeters_layout_exercise}
\usepackage{peeters_braket}
\usepackage{peeters_figures}
\usepackage{siunitx}
\usepackage{verbatim}
\usepackage{macros_cal}
%\usepackage{mhchem} % \ce{}
%\usepackage{macros_bm} % \bcM
%\usepackage{macros_qed} % \qedmarker
%\usepackage{txfonts} % \ointclockwise

\beginArtNoToc

\generatetitle{Square of electrodynamic field.}
%\chapter{Square of electrodynamic field.}
%\label{chap:fsquared}

\section{Motivation.}

The electrodynamic Lagrangian (without magnetic sources) has the form
\begin{dmath}\label{eqn:fsquared:20}
\LL = F \cdot F + a A \cdot J,
\end{dmath}
where \( a \) is a constant that depends on the unit system, \( A, J \) are a four-vectors, and \( F = \grad \wedge A \).
My suspicion is that one or both of the bivector or quadvector grades of \( F^2 \) are required for Maxwell's equation with magnetic sources.

\subsection{Square of the field.}

Let's expand out \( F^2 \) in coordinates, as preparation for computing the Euler-Lagrange equations.  The scalar and pseudoscalar components both simplify easily into compact relationships, but the bivector term is messier.  We start with the coordinate expansion of our field, which we may write in either upper or lower index form
\begin{equation}\label{eqn:fsquared:40}
   F = \inv{2} \gamma_\mu \wedge \gamma_\nu F^{\mu\nu}
    = \inv{2} \gamma^\mu \wedge \gamma^\nu F_{\mu\nu}.
\end{equation}
The square is
\begin{dmath}\label{eqn:fsquared:60}
F^2 = F \cdot F + \gpgradetwo{F^2} + F \wedge F.
\end{dmath}

Let's compute the scalar term first.  We need to make a change of dummy indexes, for one of the \( F \)'s.  It will also be convenient to use upper indexes in one factor, and lowers in the other.  We find
\begin{equation}\label{eqn:fsquared:80}
\begin{aligned}
F \cdot F
&=
\inv{4}
   \lr{ \gamma_\mu \wedge \gamma_\nu } \cdot \lr{ \gamma^\alpha \wedge \gamma^\beta }
   F^{\mu\nu}
   F_{\alpha\beta} \\
   &=
\inv{4}
\lr{
   {\delta_\nu}^\alpha {\delta_\mu}^\beta
   - {\delta_\mu}^\alpha {\delta_\nu}^\beta
}
   F^{\mu\nu}
   F_{\alpha\beta} \\
   &=
\inv{4}
\lr{
   F^{\mu\nu} F_{\nu\mu}
   -
   F^{\mu\nu} F_{\mu\nu}
} \\
&=
-\inv{2}
   F^{\mu\nu} F_{\mu\nu}.
\end{aligned}
\end{equation}

Now, let's compute the pseudoscalar component of \( F^2 \).  This time we uniformly use upper index components for the tensor, and find
\begin{equation}\label{eqn:fsquared:100}
\begin{aligned}
   F \wedge F
   &=
\inv{4}
   \lr{ \gamma_\mu \wedge \gamma_\nu } \wedge \lr{ \gamma_\alpha \wedge \gamma_\beta }
   F^{\mu\nu}
   F^{\alpha\beta} \\
   &=
   \frac{I}{4}
   \epsilon_{\mu\nu\alpha\beta} F^{\mu\nu} F^{\alpha\beta},
\end{aligned}
\end{equation}
where \( \epsilon_{\mu\nu\alpha\beta} \) is the completely antisymmetric (Levi-Civita) tensor of rank four.
This pseudoscalar components picks up all the products of components of \( F \) where all indexes are different.

Now, let's try computing the bivector term of the product.  This will require fancier index gymnastics.
\begin{equation}\label{eqn:fsquared:120}
\begin{aligned}
\gpgradetwo{F^2}
&=
\inv{4}
\gpgradetwo{
   \lr{ \gamma_\mu \wedge \gamma_\nu } \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
   F^{\mu\nu}
   F_{\alpha\beta} \\
&=
\inv{4}
\gpgradetwo{
   \gamma_\mu \gamma_\nu \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
   F^{\mu\nu}
   F_{\alpha\beta}
   -
\inv{4}
\lr{ \gamma_\mu \cdot \gamma_\nu} \lr{ \gamma^\alpha \wedge \gamma^\beta } F^{\mu\nu} F_{\alpha\beta}.
\end{aligned}
\end{equation}
The dot product term is killed, since \( \lr{ \gamma_\mu \cdot \gamma_\nu} F^{\mu\nu} = g_{\mu\nu} F^{\mu\nu} \) is the contraction of a symmetric tensor with an antisymmetric tensor.  We can now proceed to expand the grade two selection
\begin{equation}\label{eqn:fsquared:140}
\begin{aligned}
\gpgradetwo{
   \gamma_\mu \gamma_\nu \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
&=
\gamma_\mu \wedge \lr{ \gamma_\nu \cdot \lr{ \gamma^\alpha \wedge \gamma^\beta } }
   +
\gamma_\mu \cdot \lr{ \gamma_\nu \wedge \lr{ \gamma^\alpha \wedge \gamma^\beta } } \\
&=
\gamma_\mu \wedge
\lr{
   {\delta_\nu}^\alpha \gamma^\beta
   -
   {\delta_\nu}^\beta \gamma^\alpha
}
+
g_{\mu\nu} \lr{ \gamma^\alpha \wedge \gamma^\beta }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha } \\
&=
{\delta_\nu}^\alpha  \lr{ \gamma_\mu \wedge \gamma^\beta }
-
{\delta_\nu}^\beta \lr{ \gamma_\mu \wedge \gamma^\alpha }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha }.
\end{aligned}
\end{equation}
Observe that I've taken the liberty to drop the \( g_{\mu\nu} \) term.   Strictly speaking, this violated the equality, but won't matter since we will contract this with \( F^{\mu\nu} \).
We are left with
\begin{equation}\label{eqn:fsquared:160}
\begin{aligned}
   4 \gpgradetwo{ F^2 }
   &=
   \lr{
{\delta_\nu}^\alpha  \lr{ \gamma_\mu \wedge \gamma^\beta }
-
{\delta_\nu}^\beta \lr{ \gamma_\mu \wedge \gamma^\alpha }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha }
}
   F^{\mu\nu}
   F_{\alpha\beta}  \\
   &=
   F^{\mu\nu}
   \lr{
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\nu\alpha}
-
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\alpha\nu}
-
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\mu\alpha}
+
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu}
} \\
&=
   2 F^{\mu\nu}
   \lr{
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\nu\alpha}
+
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu}
} \\
&=
   2 F^{\nu\mu}
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\mu\alpha}
+
   2 F^{\mu\nu}
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu},
\end{aligned}
\end{equation}
which leaves us with
\begin{equation}\label{eqn:fsquared:180}
   \gpgradetwo{ F^2 }
   =
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F^{\mu\nu}
   F_{\alpha\mu}.
\end{equation}
I suspect that there must be an easier way to find this result.

We now have the complete coordinate expansion of \( F^2 \), separated by grade
\begin{equation}\label{eqn:fsquared:200}
   F^2 =
-\inv{2}
   F^{\mu\nu} F_{\mu\nu}
   +
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F^{\mu\nu}
   F_{\alpha\mu}
   +
   \frac{I}{4}
   \epsilon_{\mu\nu\alpha\beta} F^{\mu\nu} F^{\alpha\beta}.
\end{equation}
The next task is to start evaluating the Euler-Lagrange equations for this multivector Lagrangian density, and see what we get.  Before doing so, let's figure out what value we want for the constant \( a \).

\subsection{Maxwell's equations in STA and Tensor forms.}

We are going to use the coordinate expansion of the Lagrangian, so we need the tensor form of Maxwell's equation for comparison.

Maxwell's equations, with electric and fictional magnetic sources (useful for antenna theory and other engineering applications), are
\begin{equation}\label{eqn:fsquared:220}
\begin{aligned}
\spacegrad \cdot \BE &= \frac{\rho}{\epsilon} \\
\spacegrad \cross \BE &= - \BM - \mu \PD{t}{\BH} \\
\spacegrad \cdot \BH &= \frac{\rho_\txtm}{\mu} \\
\spacegrad \cross \BH &= \BJ + \epsilon \PD{t}{\BE}.
\end{aligned}
\end{equation}
We can assemble these into a single geometric algebra equation,
\begin{equation}\label{eqn:fsquared:240}
   \lr{ \spacegrad + \inv{c} \PD{t}{} } F = \eta \lr{ c \rho - \BJ } + I \lr{ c \rho_m - \BM },
\end{equation}
where \( F = \BE + \eta I \BH = \BE + I c \BB \).

We can put this into STA form by multiplying through by \( \gamma_0 \), making the identification \( \Be_k = \gamma_k \gamma_0 \).  For the space time derivatives, we have
\begin{equation}\label{eqn:fsquared:260}
\begin{aligned}
   \gamma_0 \lr{ \spacegrad + \inv{c} \PD{t}{} }
   &=
   \gamma_0 \lr{ \gamma_k \gamma_0 \PD{x_k}{} + \PD{x_0}{} } \\
   &=
   -\gamma_k \partial_k + \gamma_0 \partial_0 \\
   &=
   \gamma^k \partial_k + \gamma^0 \partial_0 \\
   &=
   \gamma^\mu \partial_\mu \\
   &\equiv \grad
   .
\end{aligned}
\end{equation}
For our 0,2 multivectors on the right hand side, we find, for example
\begin{equation}\label{eqn:fsquared:280}
\begin{aligned}
   \gamma_0 \eta \lr{ c \rho - \BJ }
   &=
\gamma_0 \eta c \rho - \gamma_0 \gamma_k \gamma_0 \eta (\BJ \cdot \Be_k)  \\
&=
\gamma_0 \eta c \rho + \gamma_k \eta (\BJ \cdot \Be_k)  \\
&=
\gamma_0 \frac{\rho}{\epsilon} + \gamma_k \eta (\BJ \cdot \Be_k).
\end{aligned}
\end{equation}
So, if we make the identifications
\begin{equation}\label{eqn:fsquared:300}
\begin{aligned}
   J^0 &= \frac{\rho}{\epsilon} \\
   J^k &= \eta \lr{ \BJ \cdot \Be_k } \\
   M^0 &= c \rho_m \\
   M^k &= \BM \cdot \Be_k,
\end{aligned}
\end{equation}
and \( J = J^\mu \gamma_\mu, M = M^\mu \gamma_\mu \), and \( \grad = \gamma^\mu \partial_\mu \) we find the STA form of Maxwell's equation, including magnetic sources
\begin{equation}\label{eqn:fsquared:320}
   \grad F = J - I M.
\end{equation}

The electromagnetic field, in it's STA representation is a bivector, which we can write without reference to observer specific electric and magnetic fields, as
\begin{equation}\label{eqn:fsquared:340}
   F = \inv{2} {\gamma_\mu \wedge \gamma_\nu} F^{\mu\nu},
\end{equation}
where \( F^{\mu\nu} \) is an arbitrary antisymmetric 2nd rank tensor.  Maxwell's equation has a vector and trivector component, which may be split out explicitly using grade selection, to find
\begin{equation}\label{eqn:fsquared:360}
\begin{aligned}
   \grad \cdot F &= J \\
   \grad \wedge F &= -I M.
\end{aligned}
\end{equation}

Dotting the vector equation with \( \gamma^\mu \), we have
\begin{equation}\label{eqn:fsquared:380}
\begin{aligned}
   J^\mu
   &=
   \inv{2} \gamma^\mu \cdot \lr{ \gamma^\alpha \cdot \lr{ \gamma_{\sigma} \wedge \gamma_{\pi} } \partial_\alpha F^{\sigma \pi} } \\
   &=
   \inv{2} \lr{
      {\delta^\mu}_\pi {\delta^\alpha}_\sigma
      -
      {\delta^\mu}_\sigma {\delta^\alpha}_\pi
   }
   \partial_\alpha F^{\sigma \pi}  \\
   &=
   \inv{2}
   \lr{
      \partial_\sigma F^{\sigma \mu}
      -
      \partial_\pi F^{\mu \pi}
   }
   \\
   &=
      \partial_\sigma F^{\sigma \mu}.
\end{aligned}
\end{equation}

We can find the tensor form of the trivector equation by wedging it with \( \gamma^\mu \).  On the left we have
\begin{equation}\label{eqn:fsquared:400}
\begin{aligned}
\gamma^\mu \wedge \lr{ \grad \wedge F }
&=
\inv{2} \gamma^\mu \wedge \gamma^\nu \wedge \gamma^\alpha \wedge \gamma^\beta \partial_\nu F_{\alpha\beta} \\
&=
\inv{2} I \epsilon^{\mu\nu\alpha\beta} \partial_\nu F_{\alpha\beta}.
\end{aligned}
\end{equation}
On the right, we have
\begin{equation}\label{eqn:fsquared:420}
\begin{aligned}
   \gamma^\mu \wedge \lr{ -I M }
   &=
   -\gpgrade{ \gamma^\mu I M }{4} \\
   &=
   \gpgrade{ I \gamma^\mu M }{4} \\
   &=
   I \lr{ \gamma^\mu \cdot M } \\
   &=
   I M^\mu,
\end{aligned}
\end{equation}
so we have
\begin{equation}\label{eqn:fsquared:440}
\begin{aligned}
   \partial_\nu \lr{
\inv{2}
\epsilon^{\mu\nu\alpha\beta}
F_{\alpha\beta}
}
=
M^\mu.
\end{aligned}
\end{equation}
Note that, should we want to, we can define a dual tensor \( G^{\mu\nu} = -(1/2) \epsilon^{\mu\nu\alpha\beta} F_{\alpha\beta} \), so that the electric and magnetic components of Maxwell's equation have the same structure
\begin{equation}\label{eqn:fsquared:460}
   \partial_\nu F^{\nu\mu} = J^{\mu}, \quad \partial_\nu G^{\nu\mu} = M^{\mu}.
\end{equation}

Now that we have the tensor form of Maxwell's equation, we can proceed to try to find the Lagrangian.  We will assume that the Lagrangian density for Maxwell's equation has the multivector structure
\begin{equation}\label{eqn:fsquared:480}
   \LL = \gpgrade{F^2}{0,4} + a \lr{ A \cdot J } + b I \lr{ A \cdot M},
\end{equation}
where \( F = \grad \wedge A \).  My hunch, since the multivector current has the form \( J - I M \), is that we don't actually need the grade two component of \( F^2 \), despite having spent the time computing it, thinking that it might be required.

Next time, we'll remind ourselves what the field Euler-Lagrange equations look like, and evaluate them to see if we can find the constants \(a, b\).

\subsection{Maxwell's equations for electric sources.}
Given the Lagrangian
\begin{equation}\label{eqn:fsquared:500}
\LL = F \cdot F + a \lr{ A \cdot J },
\end{equation}
we may derive Maxwell's equations from it, fixing the constant \( a \) by doing so.  We can do this three different ways, with direct variation with respect to the field components \( A_\mu \), using the Euler-Lagrange equations, or with direct variation with respect to \( A = \gamma^\mu A_\mu \), as a single four-vector field variable.

Let's try this first with direct variation using the coordinate expansion of \( A \).  The action is
\begin{equation}\label{eqn:fsquared:520}
S = \int d^4 x \lr{ -\inv{2} F_{\mu\nu} F^{\mu\nu} + a J^\mu A_\mu }.
\end{equation}
The variational principle requires the action variation to be zero for all \( \delta A_\mu \), where \( \delta A_\mu = 0 \) on the boundaries of the space.  That is
\begin{equation}\label{eqn:fsquared:540}
\begin{aligned}
0 &= \delta S  \\
  &= \int d^4 x \lr{ -\inv{2} \lr{ \delta F_{\mu\nu} } F^{\mu\nu} -\inv{2} F_{\mu\nu} \delta F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \delta F_{\mu\nu} } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \delta \lr{ \partial_\mu A_\nu - \partial_\nu A_\mu } } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \partial_\mu \delta A_\nu - \partial_\nu \delta A_\mu } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \lr{ \partial_\mu \delta A_\nu } F^{\mu\nu} - \lr{ \partial_\mu \delta A_\nu } F^{\nu\mu} } + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - 2 \lr{ \partial_\mu \delta A_\nu } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - 2 \partial_\mu \lr{ \delta A_\nu F^{\mu\nu} } + 2 \delta A_\nu \partial_\mu F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ 2 \delta A_\nu \partial_\mu F^{\mu\nu} + a J^\nu \delta A_\nu } \\
  &= \int d^4 x \lr{ 2 \partial_\mu F^{\mu\nu} + a J^\nu } \delta A_\nu.
\end{aligned}
\end{equation}
We have all the usual types of index gymnastics above, and dropped the complete derivative term since \( \delta A_\nu \) is zero on the boundary by definition.  Since the end result must be zero for all variations, we must have
\begin{equation}\label{eqn:fsquared:560}
0 = 2 \partial_\mu F^{\mu\nu} + a J^\nu.
\end{equation}
We also determine our constant \( a = -2 \).

Now, let's do the same calculation using the Euler-Lagrange equations.  We derive those by varying a general Lagrangian density, just as above
\begin{equation}\label{eqn:fsquared:580}
\begin{aligned}
   0
   &=
   \delta S  \\
   &= \int d^4 x \delta \LL(A_\mu, \partial_\nu A_\mu) \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu + \PD{(\partial_\nu A_\mu)}{\LL} \delta \partial_\nu A_\mu } \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu + \PD{(\partial_\nu A_\mu)}{\LL} \partial_\nu \delta A_\mu } \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu
   + \partial_\nu \lr{ \PD{(\partial_\nu A_\mu)}{\LL} \delta A_\mu }
   - \lr{ \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} } \delta A_\mu
} \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} - \lr{ \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} } } \delta A_\mu.
\end{aligned}
\end{equation}
Since this is zero for all variations \( \delta A_\mu \), we find the field Euler-Lagrange equations are
\begin{equation}\label{eqn:fsquared:600}
   \PD{A_\mu}{\LL} = \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} .
\end{equation}

We should be able to re-derive Maxwell's equations from the Lagrangian using these field Euler-Lagrange equations, with a bit less work, since we've pre-calculated some of the variation.  Let's try that.  Since we now know the value of the constant \( a \), our Lagrangian is
\begin{equation}\label{eqn:fsquared:620}
   \LL = -\inv{2} F_{\mu\nu} F^{\mu\nu} - 2 J^\mu A_\mu.
\end{equation}

On the LHS we have
\begin{equation}\label{eqn:fsquared:640}
\begin{aligned}
\PD{A_\mu}{\LL}
&=
\PD{A_\mu}{} \lr{ - 2 J^\nu A_\nu } \\
&=
- 2 J^\mu.
\end{aligned}
\end{equation}
For the RHS, let's first calculate
\begin{equation}\label{eqn:fsquared:660}
\begin{aligned}
\PD{(\partial_\nu A_\mu)}{\LL}
&=
\PD{(\partial_\nu A_\mu)}{}
\lr{
   -\inv{2} F_{\alpha\beta} F^{\alpha\beta}
} \\
&=
-
\lr{
   \PD{(\partial_\nu A_\mu)}{}
      F_{\alpha\beta}
}
   F^{\alpha\beta}
\\
&=
-
\lr{
   \PD{(\partial_\nu A_\mu)}{}
   \lr{
      \partial_\alpha A_\beta - \partial_\beta A_\alpha
   }
}
   F^{\alpha\beta}
\\
&=
- F^{\nu\mu}
+ F^{\mu\nu} \\
&=
- 2 F^{\nu\mu}
.
\end{aligned}
\end{equation}
We are left with
\begin{equation}\label{eqn:fsquared:680}
   -2 \partial_\nu F^{\nu\mu} = -2 J^\mu.
\end{equation}
This is the source portion of Maxwell's equation (after canceling \( -2's \)), as expected.

Now let's perform a (mostly) coordinate free evaluation of the variation.  We should be able to vary \( A \) directly without first expanding it in coordinates.

We write the field as a curl
\begin{equation}\label{eqn:fsquared:700}
   F = \grad \wedge A.
\end{equation}
For completeness sake, before continuing, since we've not already done so, we should verify that this is equivalent to the tensor expansion of \( F \) that we have been using.  We find that by expanding the gradient and the field in coordinates
\begin{equation}\label{eqn:fsquared:720}
\begin{aligned}
   F
   &= \grad \wedge A \\
   &= \lr{ \gamma^\mu \partial_\mu } \wedge \lr{ \gamma^\nu A_\nu } \\
   &= \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu \\
   &= \inv{2} \lr{
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   +
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   } \\
   &= \inv{2} \lr{
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   +
   \lr{ \gamma^\nu \wedge \gamma^\mu } \partial_\nu A_\mu
   } \\
   &= \inv{2} \
   \lr{ \gamma^\mu \wedge \gamma^\nu }
   \lr{
   \partial_\mu A_\nu - \partial_\nu A_\mu
   } \\
   &= \inv{2} \
   \lr{ \gamma^\mu \wedge \gamma^\nu } F_{\mu\nu},
\end{aligned}
\end{equation}
as claimed.

We want to expand the gradient portion of \( \grad \wedge A \), but leave the field as is.  That is
\begin{equation}\label{eqn:fsquared:740}
   \grad \wedge A = \gamma^\mu \wedge \partial_\mu A.
\end{equation}
The scalar part of \( F^2 \) is therefore
\begin{equation}\label{eqn:fsquared:760}
\begin{aligned}
F \cdot F
&=
\lr{ \gamma^\mu \wedge \partial_\mu A } \cdot \lr{ \gamma^\nu \wedge \partial_\nu A } \\
&=
\gamma^\mu \cdot \lr{ \partial_\mu A \cdot \lr{ \gamma^\nu \wedge \partial_\nu A } } \\
&=
\lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu A }
-
\lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu A) }.
\end{aligned}
\end{equation}
Our Lagrangian is now fully specified in terms of \( A \) and it's derivatives.
\begin{equation}\label{eqn:fsquared:780}
   \LL =
   \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu A }
-
\lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu A) }
- 2 J \cdot A.
\end{equation}
Observe the symmetry, with respect to index swap, in the first two terms.  This means that the variation is just
\begin{equation}\label{eqn:fsquared:800}
\begin{aligned}
   \delta \LL
&=
   2 \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta \partial_\nu A }
-
2 \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\delta \partial_\nu A) }
- 2 J \cdot \delta A
\\
&=
   2 \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu \delta A }
-
2 \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu \delta A) }
- 2 J \cdot \delta A
\\
&=
2 \partial_\nu \lr{ \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta A } }
- 2 \partial_\nu \lr{ \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot \delta A } } \\
&\quad
-2 \lr{ \partial_\nu \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta A }
+ 2 \lr{ \gamma^\mu \cdot \partial_\nu \gamma^\nu } \lr{ (\partial_\mu A) \cdot \delta A }
- 2 J \cdot \delta A \\
&=
2 (\delta A) \cdot \lr{
- \lr{ \grad \cdot \partial_\mu A } \gamma^\mu
+ \lr{ \gamma^\mu \cdot \grad } \partial_\mu A
- J
} \\
&=
2 (\delta A) \cdot \lr{
\grad \cdot \lr{ \gamma^\mu \wedge \partial_\mu A } - J
} \\
&=
2 (\delta A) \cdot \lr{
\grad \cdot F - J
}.
\end{aligned}
\end{equation}
The complete derivative term above was dropped, leaving us with the source part of Maxwell's equation
\begin{equation}\label{eqn:fsquared:820}
   \grad \cdot F = J.
\end{equation}
It makes sense that we should not have to resort to coordinates, and sure enough, we are able to avoid doing so.

We have more to do.
Questions include, how do we express the Euler-Lagrange equations without resorting to coordinates?  What form of Lagrangian do we need for magnetic charge and current densities?  Can we find Maxwell's equation in one shot from a multivector Lagrangian without resorting to coordinates, or will we need separate Lagrangians for electric and magnetic contributions?  Can we find all of Maxwell's equations without relying on conditions like \( \grad \wedge \lr{ \grad \wedge A } = 0 \) (i.e. the Biannci identity)?

\subsection{Maxwell's equations with magnetic charge and current densities, from Lagrangian.}
Now, let's suppose that we have a pseudoscalar Lagrangian density of the following form
\begin{equation}\label{eqn:fsquared:840}
\begin{aligned}
   \LL &= F \wedge F + b I A \cdot M \\
       &= \inv{4} I \epsilon^{\mu\nu\alpha\beta} F_{\mu\nu} F_{\alpha\beta} + b I A_\mu M^\mu.
\end{aligned}
\end{equation}
Let's fix \( b \) by evaluating this with the Euler-Lagrange equations
%We'll use the Euler-Lagrange equations in upper index form
%\begin{equation}\label{eqn:fsquared:860}
%   \PD{A^\alpha}{\LL} = \partial^\beta \PD{(\partial_\beta A^\alpha)}{\LL},
%\end{equation}
%and find
\begin{equation}\label{eqn:fsquared:880}
\begin{aligned}
   b I M^\alpha
   &=
   \partial_\alpha \lr{
      \inv{2} I \epsilon^{\mu\nu\sigma\pi} F_{\mu\nu} \PD{(\partial_\beta A_\alpha)}{F_{\sigma\pi}}
   } \\
   &=
      \inv{2} I \epsilon^{\mu\nu\sigma\pi}
   \partial_\alpha \lr{
      F_{\mu\nu} \PD{(\partial_\beta A_\alpha)}{}\lr{\partial_\sigma A_\pi - \partial_\pi A_\sigma}
   } \\
   &=
      \inv{2} I
   \partial_\alpha \lr{
      \epsilon^{\mu\nu\beta\alpha}
      F_{\mu\nu}
      -
      \epsilon^{\mu\nu\alpha\beta}
      F_{\mu\nu}
   } \\
   &=
      I
   \partial_\alpha
      \epsilon^{\mu\nu\beta\alpha}
      F_{\mu\nu}
\end{aligned}
\end{equation}
Remember that we want \(
   \partial_\nu \lr{
\inv{2}
\epsilon^{\mu\nu\alpha\beta}
F_{\alpha\beta}
}
=
M^\mu \), so after swapping indexes we see that \( b = 2 \).

We would find the same thing if we vary the Lagrangian directly with respect to variations \( \delta A_\mu \).  However, let's try that variation with respect to a four-vector field variable \( \delta A \) instead.  Our multivector Lagrangian is
\begin{equation}\label{eqn:fsquared:900}
\begin{aligned}
   \LL
   &= F \wedge F + 2 I M \cdot A \\
   &=
   \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \partial_\nu A } + 2 (I M) \wedge A.
\end{aligned}
\end{equation}
We've used a duality transformation on the current term that will come in handy shortly.  The Lagrangian variation is
\begin{equation}\label{eqn:fsquared:920}
\begin{aligned}
\delta \LL
&=
   2 \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta \partial_\nu A } + 2 (I M) \wedge \delta A \\
&=
   2 \partial_\nu \lr{ \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta A } }
   -
   2 \lr{ \gamma^\mu \wedge \partial_\nu \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta A }
   + 2 (I M) \wedge \delta A \\
&=
   2 \lr{ - \lr{ \gamma^\mu \wedge \partial_\nu \partial_\mu A } \wedge \gamma^\nu + I M } \wedge \delta A \\
&=
2 \lr{ - \grad \wedge (\partial_\nu A ) \wedge \gamma^\nu + I M } \wedge \delta A.
\end{aligned}
\end{equation}
We've dropped the complete derivative term, as the \( \delta A \) is zero on the boundary.   For the action variation to be zero, we require
\begin{equation}\label{eqn:fsquared:940}
\begin{aligned}
   0
   &= - \grad \wedge (\partial_\nu A ) \wedge \gamma^\nu + I M \\
   &= \grad \wedge \gamma^\nu \wedge (\partial_\nu A ) + I M \\
   &= \grad \wedge \lr{ \grad \wedge A } + I M \\
   &= \grad \wedge F + I M,
\end{aligned}
\end{equation}
or
\begin{equation}\label{eqn:fsquared:960}
   \grad \wedge F = -I M.
\end{equation}
Here we've had to dodge a sneaky detail, namely that \( \grad \wedge \lr{ \grad \wedge A } = 0 \), provided \( A \) has sufficient continuity that we can assert mixed partials.  We will see a way to resolve this contradiction when we vary a Lagrangian density that includes both electric and magnetic field contributions.  That's a game for a different day.

\subsection{Multivector Lagrangian for Maxwell's equation.}
We've found the charge and currency dependency parts of Maxwell's equations for both electric and magnetic sources, using scalar and pseudoscalar Lagrangian densities respectively.

Now comes the really cool part.  We can form a multivector Lagrangian and find Maxwell's equation in it's entirety in a single operation, without resorting to usual coordinate expansion of the fields.

Our Lagrangian is
\begin{equation}\label{eqn:fsquared:980}
   \LL = \inv{2} F^2 - \gpgrade{A \lr{ J - I M}}{0,4},
\end{equation}
where \( F = \grad \wedge A \).

The variation of the action formed from this Lagrangian density is
\begin{equation}\label{eqn:fsquared:1000}
   \delta S = \int d^4 x \lr{
      \inv{2} \lr{ F \delta F + (\delta F) F } - \gpgrade{ \delta A \lr{ J - I M} }{0,4}
   }.
\end{equation}
Both \( F \) and \( \delta F \) are STA bivectors, and for any two bivectors the symmetric sum of their products, selects the grade 0,4 components of the product.  That is, for bivectors, \( F, G \), we have
\begin{equation}\label{eqn:fsquared:1020}
   \inv{2}\lr{ F G + G F } = \gpgrade{F G}{0,4} = \gpgrade{G F}{0,4}.
\end{equation}
This means that the action variation integrand can all be placed into a 0,4 grade selection operation
\begin{equation}\label{eqn:fsquared:1040}
   \delta S
   = \int d^4 x \gpgrade{
      (\delta F) F - \delta A \lr{ J - I M}
   }{0,4}.
\end{equation}
Let's look at the \( (\delta F) F \) multivector in more detail
\begin{equation}\label{eqn:fsquared:1060}
\begin{aligned}
(\delta F) F
&=
\delta \lr{ \gamma^\mu \wedge \partial_\mu A } F \\
&=
\lr{ \gamma^\mu \wedge \delta \partial_\mu A } F \\
&=
   \lr{ \gamma^\mu \wedge \partial_\mu \delta A } F \\
&=
-
\lr{ (\partial_\mu \delta A) \wedge \gamma^\mu } F \\
&=
-
(\partial_\mu \delta A) \gamma^\mu F
-
\lr{ (\partial_\mu \delta A) \cdot \gamma^\mu } F
\\
\end{aligned}
\end{equation}
This second term is a bivector, so once filtered with a grade 0,4 selection operator, will be obliterated.
We are left with
\begin{equation}\label{eqn:fsquared:1080}
\begin{aligned}
   \delta S
   &= \int d^4 x \gpgrade{
-
(\partial_\mu \delta A) \gamma^\mu F
      - \delta A \lr{ J - I M}
   }{0,4}
   \\
   &= \int d^4 x \gpgrade{
-
\partial_\mu \lr{
\delta A \gamma^\mu F
}
+ \delta A \gamma^\mu \partial_\mu F
      - \delta A \lr{ J - I M}
   }{0,4}
   \\
   &= \int d^4 x
   \gpgrade{
      \delta A \lr{ \grad F - \lr{ J - I M} }
}{0,4}.
\end{aligned}
\end{equation}
As before, the total derivative term has been dropped, as variations \( \delta A \) are zero on the boundary.  The remaining integrand must be zero for all variations, so we conclude that
\begin{equation}\label{eqn:fsquared:1100}
   \boxed{
   \grad F = J - I M.
}
\end{equation}
Almost magically, out pops Maxwell's equation in it's full glory, with both four vector charge and current density, and also the trivector (fictitious) magnetic charge and current densities, should we want to include those.

\subsubsection{A final detail.}
There's one last thing to say.  If you have a nagging objection to me having declared that \( \grad F - \lr{ J - I M} = 0 \) when the whole integrand was enclosed in a grade 0,4 selection operator.  Shouldn't we have to account for the grade selection operator somehow?  Yes, we should, and I cheated a bit to not do so, but we get the same answer if we do.  To handle this with a bit more finesse, we split \( \grad F - \lr{ J - I M}  \) into it's vector and trivector components, and consider those separately
\begin{equation}\label{eqn:fsquared:1120}
\gpgrade{
      \delta A \lr{ \grad F - \lr{ J - I M} }
}{0,4}
=
\delta A \cdot \lr{ \grad \cdot F - J }
+
\delta A \wedge \lr{ \grad \wedge F + I M }.
\end{equation}
We require these to be zero for all variations \( \delta A \), which gives us two independent equations
\begin{equation}\label{eqn:fsquared:1140}
\begin{aligned}
   \grad \cdot F - \lr{ J - I M}  &= 0 \\
   \grad \wedge F + I M &= 0.
\end{aligned}
\end{equation}
However, we can now add up these equations, using \( \grad F = \grad \cdot F + \grad \wedge F \) to find, sure enough, that
\begin{equation}\label{eqn:fsquared:1160}
   \grad F = J - I M,
\end{equation}
as stated, somewhat sloppily, before.

%}
%\EndArticle
\EndNoBibArticle
