%
% Copyright © 2022 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\input{../latex/blogpost.tex}
\renewcommand{\basename}{fsquared}
%\renewcommand{\dirname}{notes/phy1520/}
\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}

\input{../latex/peeter_prologue_print2.tex}

\usepackage{peeters_layout_exercise}
\usepackage{peeters_braket}
\usepackage{peeters_figures}
\usepackage{siunitx}
\usepackage{verbatim}
\usepackage{macros_cal}
%\usepackage{mhchem} % \ce{}
%\usepackage{macros_bm} % \bcM
%\usepackage{macros_qed} % \qedmarker
%\usepackage{txfonts} % \ointclockwise

\beginArtNoToc

\generatetitle{Square of electrodynamic field.}
%\chapter{Square of electrodynamic field.}
%\label{chap:fsquared}

\section{Motivation.}

The electrodynamic Lagrangian (without magnetic sources) has the form
\begin{dmath}\label{eqn:fsquared:20}
\LL = F \cdot F + a A \cdot J,
\end{dmath}
where \( a \) is a constant that depends on the unit system, \( A, J \) are a four-vectors, and \( F = \grad \wedge A \).
My suspicion is that one or both of the bivector or quadvector grades of \( F^2 \) are required for Maxwell's equation with magnetic sources.

\section{Square of the field.}
Let's expand out \( F^2 \) in coordinates, as preparation for computing the Euler-Lagrange equations.  The scalar and pseudoscalar components both simplify easily into compact relationships, but the bivector term is messier.  We start with the coordinate expansion of our field, which we may write in either upper or lower index form
\begin{equation}\label{eqn:fsquared:40}
   F = \inv{2} \gamma_\mu \wedge \gamma_\nu F^{\mu\nu}
    = \inv{2} \gamma^\mu \wedge \gamma^\nu F_{\mu\nu}.
\end{equation}
The square is
\begin{dmath}\label{eqn:fsquared:60}
F^2 = F \cdot F + \gpgradetwo{F^2} + F \wedge F.
\end{dmath}

Let's compute the scalar term first.  We need to make a change of dummy indexes, for one of the \( F \)'s.  It will also be convenient to use upper indexes in one factor, and lowers in the other.  We find
\begin{equation}\label{eqn:fsquared:80}
\begin{aligned}
F \cdot F
&=
\inv{4}
   \lr{ \gamma_\mu \wedge \gamma_\nu } \cdot \lr{ \gamma^\alpha \wedge \gamma^\beta }
   F^{\mu\nu}
   F_{\alpha\beta} \\
   &=
\inv{4}
\lr{
   {\delta_\nu}^\alpha {\delta_\mu}^\beta
   - {\delta_\mu}^\alpha {\delta_\nu}^\beta
}
   F^{\mu\nu}
   F_{\alpha\beta} \\
   &=
\inv{4}
\lr{
   F^{\mu\nu} F_{\nu\mu}
   -
   F^{\mu\nu} F_{\mu\nu}
} \\
&=
-\inv{2}
   F^{\mu\nu} F_{\mu\nu}.
\end{aligned}
\end{equation}

Now, let's compute the pseudoscalar component of \( F^2 \).  This time we uniformly use upper index components for the tensor, and find
\begin{equation}\label{eqn:fsquared:100}
\begin{aligned}
   F \wedge F
   &=
\inv{4}
   \lr{ \gamma_\mu \wedge \gamma_\nu } \wedge \lr{ \gamma_\alpha \wedge \gamma_\beta }
   F^{\mu\nu}
   F^{\alpha\beta} \\
   &=
   \frac{I}{4}
   \epsilon_{\mu\nu\alpha\beta} F^{\mu\nu} F^{\alpha\beta},
\end{aligned}
\end{equation}
where \( \epsilon_{\mu\nu\alpha\beta} \) is the completely antisymmetric (Levi-Civita) tensor of rank four.
This pseudoscalar components picks up all the products of components of \( F \) where all indexes are different.

Now, let's try computing the bivector term of the product.  This will require fancier index gymnastics.
\begin{equation}\label{eqn:fsquared:120}
\begin{aligned}
\gpgradetwo{F^2}
&=
\inv{4}
\gpgradetwo{
   \lr{ \gamma_\mu \wedge \gamma_\nu } \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
   F^{\mu\nu}
   F_{\alpha\beta} \\
&=
\inv{4}
\gpgradetwo{
   \gamma_\mu \gamma_\nu \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
   F^{\mu\nu}
   F_{\alpha\beta}
   -
\inv{4}
\lr{ \gamma_\mu \cdot \gamma_\nu} \lr{ \gamma^\alpha \wedge \gamma^\beta } F^{\mu\nu} F_{\alpha\beta}.
\end{aligned}
\end{equation}
The dot product term is killed, since \( \lr{ \gamma_\mu \cdot \gamma_\nu} F^{\mu\nu} = g_{\mu\nu} F^{\mu\nu} \) is the contraction of a symmetric tensor with an antisymmetric tensor.  We can now proceed to expand the grade two selection
\begin{equation}\label{eqn:fsquared:140}
\begin{aligned}
\gpgradetwo{
   \gamma_\mu \gamma_\nu \lr{ \gamma^\alpha \wedge \gamma^\beta }
}
&=
\gamma_\mu \wedge \lr{ \gamma_\nu \cdot \lr{ \gamma^\alpha \wedge \gamma^\beta } }
   +
\gamma_\mu \cdot \lr{ \gamma_\nu \wedge \lr{ \gamma^\alpha \wedge \gamma^\beta } } \\
&=
\gamma_\mu \wedge
\lr{
   {\delta_\nu}^\alpha \gamma^\beta
   -
   {\delta_\nu}^\beta \gamma^\alpha
}
+
g_{\mu\nu} \lr{ \gamma^\alpha \wedge \gamma^\beta }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha } \\
&=
{\delta_\nu}^\alpha  \lr{ \gamma_\mu \wedge \gamma^\beta }
-
{\delta_\nu}^\beta \lr{ \gamma_\mu \wedge \gamma^\alpha }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha }.
\end{aligned}
\end{equation}
Observe that I've taken the liberty to drop the \( g_{\mu\nu} \) term.   Strictly speaking, this violated the equality, but won't matter since we will contract this with \( F^{\mu\nu} \).
We are left with
\begin{equation}\label{eqn:fsquared:160}
\begin{aligned}
   4 \gpgradetwo{ F^2 }
   &=
   \lr{
{\delta_\nu}^\alpha  \lr{ \gamma_\mu \wedge \gamma^\beta }
-
{\delta_\nu}^\beta \lr{ \gamma_\mu \wedge \gamma^\alpha }
-
{\delta_\mu}^\alpha \lr{ \gamma_\nu \wedge \gamma^\beta }
+
{\delta_\mu}^\beta \lr{ \gamma_\nu \wedge \gamma^\alpha }
}
   F^{\mu\nu}
   F_{\alpha\beta}  \\
   &=
   F^{\mu\nu}
   \lr{
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\nu\alpha}
-
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\alpha\nu}
-
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\mu\alpha}
+
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu}
} \\
&=
   2 F^{\mu\nu}
   \lr{
\lr{ \gamma_\mu \wedge \gamma^\alpha }
   F_{\nu\alpha}
+
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu}
} \\
&=
   2 F^{\nu\mu}
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\mu\alpha}
+
   2 F^{\mu\nu}
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F_{\alpha\mu},
\end{aligned}
\end{equation}
which leaves us with
\begin{equation}\label{eqn:fsquared:180}
   \gpgradetwo{ F^2 }
   =
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F^{\mu\nu}
   F_{\alpha\mu}.
\end{equation}
I suspect that there must be an easier way to find this result.

We now have the complete coordinate expansion of \( F^2 \), separated by grade
\begin{equation}\label{eqn:fsquared:200}
   F^2 =
-\inv{2}
   F^{\mu\nu} F_{\mu\nu}
   +
\lr{ \gamma_\nu \wedge \gamma^\alpha }
   F^{\mu\nu}
   F_{\alpha\mu}
   +
   \frac{I}{4}
   \epsilon_{\mu\nu\alpha\beta} F^{\mu\nu} F^{\alpha\beta}.
\end{equation}
The next task is to start evaluating the Euler-Lagrange equations for this multivector Lagrangian density, and see what we get.  Before doing so, let's figure out what value we want for the constant \( a \).
\section{Maxwell's equations in STA and Tensor forms.}
We are going to use the coordinate expansion of the Lagrangian, so we need the tensor form of Maxwell's equation for comparison.

Maxwell's equations, with electric and fictional magnetic sources (useful for antenna theory and other engineering applications), are
\begin{equation}\label{eqn:fsquared:220}
\begin{aligned}
\spacegrad \cdot \BE &= \frac{\rho}{\epsilon} \\
\spacegrad \cross \BE &= - \BM - \mu \PD{t}{\BH} \\
\spacegrad \cdot \BH &= \frac{\rho_\txtm}{\mu} \\
\spacegrad \cross \BH &= \BJ + \epsilon \PD{t}{\BE}.
\end{aligned}
\end{equation}
We can assemble these into a single geometric algebra equation,
\begin{equation}\label{eqn:fsquared:240}
   \lr{ \spacegrad + \inv{c} \PD{t}{} } F = \eta \lr{ c \rho - \BJ } + I \lr{ c \rho_m - \BM },
\end{equation}
where \( F = \BE + \eta I \BH = \BE + I c \BB \).

We can put this into STA form by multiplying through by \( \gamma_0 \), making the identification \( \Be_k = \gamma_k \gamma_0 \).  For the space time derivatives, we have
\begin{equation}\label{eqn:fsquared:260}
\begin{aligned}
   \gamma_0 \lr{ \spacegrad + \inv{c} \PD{t}{} }
   &=
   \gamma_0 \lr{ \gamma_k \gamma_0 \PD{x_k}{} + \PD{x_0}{} } \\
   &=
   -\gamma_k \partial_k + \gamma_0 \partial_0 \\
   &=
   \gamma^k \partial_k + \gamma^0 \partial_0 \\
   &=
   \gamma^\mu \partial_\mu \\
   &\equiv \grad
   .
\end{aligned}
\end{equation}
For our 0,2 multivectors on the right hand side, we find, for example
\begin{equation}\label{eqn:fsquared:280}
\begin{aligned}
   \gamma_0 \eta \lr{ c \rho - \BJ }
   &=
\gamma_0 \eta c \rho - \gamma_0 \gamma_k \gamma_0 \eta (\BJ \cdot \Be_k)  \\
&=
\gamma_0 \eta c \rho + \gamma_k \eta (\BJ \cdot \Be_k)  \\
&=
\gamma_0 \frac{\rho}{\epsilon} + \gamma_k \eta (\BJ \cdot \Be_k).
\end{aligned}
\end{equation}
So, if we make the identifications
\begin{equation}\label{eqn:fsquared:300}
\begin{aligned}
   J^0 &= \frac{\rho}{\epsilon} \\
   J^k &= \eta \lr{ \BJ \cdot \Be_k } \\
   M^0 &= c \rho_m \\
   M^k &= \BM \cdot \Be_k,
\end{aligned}
\end{equation}
and \( J = J^\mu \gamma_\mu, M = M^\mu \gamma_\mu \), and \( \grad = \gamma^\mu \partial_\mu \) we find the STA form of Maxwell's equation, including magnetic sources
\begin{equation}\label{eqn:fsquared:320}
   \grad F = J - I M.
\end{equation}

The electromagnetic field, in the STA representation is a bivector, which we can write without reference to observer specific electric and magnetic fields, as
\begin{equation}\label{eqn:fsquared:340}
   F = \inv{2} {\gamma_\mu \wedge \gamma_\nu} F^{\mu\nu},
\end{equation}
where \( F^{\mu\nu} \) is an arbitrary antisymmetric 2nd rank tensor.  Maxwell's equation has a vector and trivector component, which may be split out explicitly using grade selection, to find
\begin{equation}\label{eqn:fsquared:360}
\begin{aligned}
   \grad \cdot F &= J \\
   \grad \wedge F &= -I M.
\end{aligned}
\end{equation}

Dotting the vector equation with \( \gamma^\mu \), we have
\begin{equation}\label{eqn:fsquared:380}
\begin{aligned}
   J^\mu
   &=
   \inv{2} \gamma^\mu \cdot \lr{ \gamma^\alpha \cdot \lr{ \gamma_{\sigma} \wedge \gamma_{\pi} } \partial_\alpha F^{\sigma \pi} } \\
   &=
   \inv{2} \lr{
      {\delta^\mu}_\pi {\delta^\alpha}_\sigma
      -
      {\delta^\mu}_\sigma {\delta^\alpha}_\pi
   }
   \partial_\alpha F^{\sigma \pi}  \\
   &=
   \inv{2}
   \lr{
      \partial_\sigma F^{\sigma \mu}
      -
      \partial_\pi F^{\mu \pi}
   }
   \\
   &=
      \partial_\sigma F^{\sigma \mu}.
\end{aligned}
\end{equation}

We can find the tensor form of the trivector equation by wedging it with \( \gamma^\mu \).  On the left we have
\begin{equation}\label{eqn:fsquared:400}
\begin{aligned}
\gamma^\mu \wedge \lr{ \grad \wedge F }
&=
\inv{2} \gamma^\mu \wedge \gamma^\nu \wedge \gamma^\alpha \wedge \gamma^\beta \partial_\nu F_{\alpha\beta} \\
&=
\inv{2} I \epsilon^{\mu\nu\alpha\beta} \partial_\nu F_{\alpha\beta}.
\end{aligned}
\end{equation}
On the right, we have
\begin{equation}\label{eqn:fsquared:420}
\begin{aligned}
   \gamma^\mu \wedge \lr{ -I M }
   &=
   -\gpgrade{ \gamma^\mu I M }{4} \\
   &=
   \gpgrade{ I \gamma^\mu M }{4} \\
   &=
   I \lr{ \gamma^\mu \cdot M } \\
   &=
   I M^\mu,
\end{aligned}
\end{equation}
so we have
\begin{equation}\label{eqn:fsquared:440}
\begin{aligned}
   \partial_\nu \lr{
\inv{2}
\epsilon^{\mu\nu\alpha\beta}
F_{\alpha\beta}
}
=
M^\mu.
\end{aligned}
\end{equation}
Note that, should we want to, we can define a dual tensor \( G^{\mu\nu} = -(1/2) \epsilon^{\mu\nu\alpha\beta} F_{\alpha\beta} \), so that the electric and magnetic components of Maxwell's equation have the same structure
\begin{equation}\label{eqn:fsquared:460}
   \partial_\nu F^{\nu\mu} = J^{\mu}, \quad \partial_\nu G^{\nu\mu} = M^{\mu}.
\end{equation}

Now that we have the tensor form of Maxwell's equation, we can proceed to try to find the Lagrangian.  We will assume that the Lagrangian density for Maxwell's equation has the multivector structure
\begin{equation}\label{eqn:fsquared:480}
   \LL = \gpgrade{F^2}{0,4} + a \lr{ A \cdot J } + b I \lr{ A \cdot M},
\end{equation}
where \( F = \grad \wedge A \).  My hunch, since the multivector current has the form \( J - I M \), is that we don't actually need the grade two component of \( F^2 \), despite having spent the time computing it, thinking that it might be required.

Next, we'll remind ourselves what the field Euler-Lagrange equations look like, and evaluate them to see if we can find the constants \(a, b\).
\section{Maxwell's equations for electric sources.}
Given the Lagrangian
\begin{equation}\label{eqn:fsquared:500}
\LL = F \cdot F + a \lr{ A \cdot J },
\end{equation}
we may derive Maxwell's equations from it, fixing the constant \( a \) by doing so.  We can do this three different ways, with direct variation with respect to the field components \( A_\mu \), using the Euler-Lagrange equations, or with direct variation with respect to \( A = \gamma^\mu A_\mu \), as a single four-vector field variable.

Let's try this first with direct variation using the coordinate expansion of \( A \).  The action is
\begin{equation}\label{eqn:fsquared:520}
S = \int d^4 x \lr{ -\inv{2} F_{\mu\nu} F^{\mu\nu} + a J^\mu A_\mu }.
\end{equation}
The variational principle requires the action variation to be zero for all \( \delta A_\mu \), where \( \delta A_\mu = 0 \) on the boundaries of the space.  That is
\begin{equation}\label{eqn:fsquared:540}
\begin{aligned}
0 &= \delta S  \\
  &= \int d^4 x \lr{ -\inv{2} \lr{ \delta F_{\mu\nu} } F^{\mu\nu} -\inv{2} F_{\mu\nu} \delta F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \delta F_{\mu\nu} } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \delta \lr{ \partial_\mu A_\nu - \partial_\nu A_\mu } } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \partial_\mu \delta A_\nu - \partial_\nu \delta A_\mu } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - \lr{ \lr{ \partial_\mu \delta A_\nu } F^{\mu\nu} - \lr{ \partial_\mu \delta A_\nu } F^{\nu\mu} } + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - 2 \lr{ \partial_\mu \delta A_\nu } F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ - 2 \partial_\mu \lr{ \delta A_\nu F^{\mu\nu} } + 2 \delta A_\nu \partial_\mu F^{\mu\nu} + a J^\mu \delta A_\mu } \\
  &= \int d^4 x \lr{ 2 \delta A_\nu \partial_\mu F^{\mu\nu} + a J^\nu \delta A_\nu } \\
  &= \int d^4 x \lr{ 2 \partial_\mu F^{\mu\nu} + a J^\nu } \delta A_\nu.
\end{aligned}
\end{equation}
We have all the usual types of index gymnastics above, and dropped the complete derivative term since \( \delta A_\nu \) is zero on the boundary by definition.  Since the end result must be zero for all variations, we must have
\begin{equation}\label{eqn:fsquared:560}
0 = 2 \partial_\mu F^{\mu\nu} + a J^\nu.
\end{equation}
We also determine our constant \( a = -2 \).

Now, let's do the same calculation using the Euler-Lagrange equations.  We derive those by varying a general Lagrangian density, just as above
\begin{equation}\label{eqn:fsquared:580}
\begin{aligned}
   0
   &=
   \delta S  \\
   &= \int d^4 x \delta \LL(A_\mu, \partial_\nu A_\mu) \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu + \PD{(\partial_\nu A_\mu)}{\LL} \delta \partial_\nu A_\mu } \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu + \PD{(\partial_\nu A_\mu)}{\LL} \partial_\nu \delta A_\mu } \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} \delta A_\mu
   + \partial_\nu \lr{ \PD{(\partial_\nu A_\mu)}{\LL} \delta A_\mu }
   - \lr{ \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} } \delta A_\mu
} \\
   &= \int d^4 x \lr{ \PD{A_\mu}{\LL} - \lr{ \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} } } \delta A_\mu.
\end{aligned}
\end{equation}
Since this is zero for all variations \( \delta A_\mu \), we find the field Euler-Lagrange equations are
\begin{equation}\label{eqn:fsquared:600}
   \PD{A_\mu}{\LL} = \partial_\nu \PD{(\partial_\nu A_\mu)}{\LL} .
\end{equation}

We should be able to re-derive Maxwell's equations from the Lagrangian using these field Euler-Lagrange equations, with a bit less work, since we've pre-calculated some of the variation.  Let's try that.  Since we now know the value of the constant \( a \), our Lagrangian is
\begin{equation}\label{eqn:fsquared:620}
   \LL = -\inv{2} F_{\mu\nu} F^{\mu\nu} - 2 J^\mu A_\mu.
\end{equation}

On the LHS we have
\begin{equation}\label{eqn:fsquared:640}
\begin{aligned}
\PD{A_\mu}{\LL}
&=
\PD{A_\mu}{} \lr{ - 2 J^\nu A_\nu } \\
&=
- 2 J^\mu.
\end{aligned}
\end{equation}
For the RHS, let's first calculate
\begin{equation}\label{eqn:fsquared:660}
\begin{aligned}
\PD{(\partial_\nu A_\mu)}{\LL}
&=
\PD{(\partial_\nu A_\mu)}{}
\lr{
   -\inv{2} F_{\alpha\beta} F^{\alpha\beta}
} \\
&=
-
\lr{
   \PD{(\partial_\nu A_\mu)}{}
      F_{\alpha\beta}
}
   F^{\alpha\beta}
\\
&=
-
\lr{
   \PD{(\partial_\nu A_\mu)}{}
   \lr{
      \partial_\alpha A_\beta - \partial_\beta A_\alpha
   }
}
   F^{\alpha\beta}
\\
&=
- F^{\nu\mu}
+ F^{\mu\nu} \\
&=
- 2 F^{\nu\mu}
.
\end{aligned}
\end{equation}
We are left with
\begin{equation}\label{eqn:fsquared:680}
   -2 \partial_\nu F^{\nu\mu} = -2 J^\mu.
\end{equation}
This is the source portion of Maxwell's equation (after canceling \( -2's \)), as expected.

Now let's perform a (mostly) coordinate free evaluation of the variation.  We should be able to vary \( A \) directly without first expanding it in coordinates.

We write the field as a curl
\begin{equation}\label{eqn:fsquared:700}
   F = \grad \wedge A.
\end{equation}
For completeness sake, before continuing, since we've not already done so, we should verify that this is equivalent to the tensor expansion of \( F \) that we have been using.  We find that by expanding the gradient and the field in coordinates
\begin{equation}\label{eqn:fsquared:720}
\begin{aligned}
   F
   &= \grad \wedge A \\
   &= \lr{ \gamma^\mu \partial_\mu } \wedge \lr{ \gamma^\nu A_\nu } \\
   &= \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu \\
   &= \inv{2} \lr{
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   +
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   } \\
   &= \inv{2} \lr{
   \lr{ \gamma^\mu \wedge \gamma^\nu } \partial_\mu A_\nu
   +
   \lr{ \gamma^\nu \wedge \gamma^\mu } \partial_\nu A_\mu
   } \\
   &= \inv{2} \
   \lr{ \gamma^\mu \wedge \gamma^\nu }
   \lr{
   \partial_\mu A_\nu - \partial_\nu A_\mu
   } \\
   &= \inv{2} \
   \lr{ \gamma^\mu \wedge \gamma^\nu } F_{\mu\nu},
\end{aligned}
\end{equation}
as claimed.

We want to expand the gradient portion of \( \grad \wedge A \), but leave the field as is.  That is
\begin{equation}\label{eqn:fsquared:740}
   \grad \wedge A = \gamma^\mu \wedge \partial_\mu A.
\end{equation}
The scalar part of \( F^2 \) is therefore
\begin{equation}\label{eqn:fsquared:760}
\begin{aligned}
F \cdot F
&=
\lr{ \gamma^\mu \wedge \partial_\mu A } \cdot \lr{ \gamma^\nu \wedge \partial_\nu A } \\
&=
\gamma^\mu \cdot \lr{ \partial_\mu A \cdot \lr{ \gamma^\nu \wedge \partial_\nu A } } \\
&=
\lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu A }
-
\lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu A) }.
\end{aligned}
\end{equation}
Our Lagrangian is now fully specified in terms of \( A \) and it's derivatives.
\begin{equation}\label{eqn:fsquared:780}
   \LL =
   \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu A }
-
\lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu A) }
- 2 J \cdot A.
\end{equation}
Observe the symmetry, with respect to index swap, in the first two terms.  This means that the variation is just
\begin{equation}\label{eqn:fsquared:800}
\begin{aligned}
   \delta \LL
&=
   2 \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta \partial_\nu A }
-
2 \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\delta \partial_\nu A) }
- 2 J \cdot \delta A
\\
&=
   2 \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \partial_\nu \delta A }
-
2 \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot (\partial_\nu \delta A) }
- 2 J \cdot \delta A
\\
&=
2 \partial_\nu \lr{ \lr{ \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta A } }
- 2 \partial_\nu \lr{ \lr{ \gamma^\mu \cdot \gamma^\nu } \lr{ (\partial_\mu A) \cdot \delta A } } \\
&\quad
-2 \lr{ \partial_\nu \gamma^\nu \cdot \partial_\mu A } \lr{ \gamma^\mu \cdot \delta A }
+ 2 \lr{ \gamma^\mu \cdot \partial_\nu \gamma^\nu } \lr{ (\partial_\mu A) \cdot \delta A }
- 2 J \cdot \delta A \\
&=
2 (\delta A) \cdot \lr{
- \lr{ \grad \cdot \partial_\mu A } \gamma^\mu
+ \lr{ \gamma^\mu \cdot \grad } \partial_\mu A
- J
} \\
&=
2 (\delta A) \cdot \lr{
\grad \cdot \lr{ \gamma^\mu \wedge \partial_\mu A } - J
} \\
&=
2 (\delta A) \cdot \lr{
\grad \cdot F - J
}.
\end{aligned}
\end{equation}
The complete derivative term above was dropped, leaving us with the source part of Maxwell's equation
\begin{equation}\label{eqn:fsquared:820}
   \grad \cdot F = J.
\end{equation}
It makes sense that we should not have to resort to coordinates, and sure enough, we are able to avoid doing so.

We have more to do.
Questions include, how do we express the Euler-Lagrange equations without resorting to coordinates?  What form of Lagrangian do we need for magnetic charge and current densities?  Can we find Maxwell's equation in one shot from a multivector Lagrangian without resorting to coordinates, or will we need separate Lagrangians for electric and magnetic contributions?  Can we find all of Maxwell's equations without relying on conditions like \( \grad \wedge \lr{ \grad \wedge A } = 0 \) (i.e. the Biannci identity)?
\section{Maxwell's equations with magnetic charge and current densities, from Lagrangian.}
Now, let's suppose that we have a pseudoscalar Lagrangian density of the following form
\begin{equation}\label{eqn:fsquared:840}
\begin{aligned}
   \LL &= F \wedge F + b I A \cdot M \\
       &= \inv{4} I \epsilon^{\mu\nu\alpha\beta} F_{\mu\nu} F_{\alpha\beta} + b I A_\mu M^\mu.
\end{aligned}
\end{equation}
Let's fix \( b \) by evaluating this with the Euler-Lagrange equations
%We'll use the Euler-Lagrange equations in upper index form
%\begin{equation}\label{eqn:fsquared:860}
%   \PD{A^\alpha}{\LL} = \partial^\beta \PD{(\partial_\beta A^\alpha)}{\LL},
%\end{equation}
%and find
\begin{equation}\label{eqn:fsquared:880}
\begin{aligned}
   b I M^\alpha
   &=
   \partial_\alpha \lr{
      \inv{2} I \epsilon^{\mu\nu\sigma\pi} F_{\mu\nu} \PD{(\partial_\beta A_\alpha)}{F_{\sigma\pi}}
   } \\
   &=
      \inv{2} I \epsilon^{\mu\nu\sigma\pi}
   \partial_\alpha \lr{
      F_{\mu\nu} \PD{(\partial_\beta A_\alpha)}{}\lr{\partial_\sigma A_\pi - \partial_\pi A_\sigma}
   } \\
   &=
      \inv{2} I
   \partial_\alpha \lr{
      \epsilon^{\mu\nu\beta\alpha}
      F_{\mu\nu}
      -
      \epsilon^{\mu\nu\alpha\beta}
      F_{\mu\nu}
   } \\
   &=
      I
   \partial_\alpha
      \epsilon^{\mu\nu\beta\alpha}
      F_{\mu\nu}
\end{aligned}
\end{equation}
Remember that we want \(
   \partial_\nu \lr{
\inv{2}
\epsilon^{\mu\nu\alpha\beta}
F_{\alpha\beta}
}
=
M^\mu \), so after swapping indexes we see that \( b = 2 \).

We would find the same thing if we vary the Lagrangian directly with respect to variations \( \delta A_\mu \).  However, let's try that variation with respect to a four-vector field variable \( \delta A \) instead.  Our multivector Lagrangian is
\begin{equation}\label{eqn:fsquared:900}
\begin{aligned}
   \LL
   &= F \wedge F + 2 I M \cdot A \\
   &=
   \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \partial_\nu A } + 2 (I M) \wedge A.
\end{aligned}
\end{equation}
We've used a duality transformation on the current term that will come in handy shortly.  The Lagrangian variation is
\begin{equation}\label{eqn:fsquared:920}
\begin{aligned}
\delta \LL
&=
   2 \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta \partial_\nu A } + 2 (I M) \wedge \delta A \\
&=
   2 \partial_\nu \lr{ \lr{ \gamma^\mu \wedge \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta A } }
   -
   2 \lr{ \gamma^\mu \wedge \partial_\nu \partial_\mu A } \wedge \lr{ \gamma^\nu \wedge \delta A }
   + 2 (I M) \wedge \delta A \\
&=
   2 \lr{ - \lr{ \gamma^\mu \wedge \partial_\nu \partial_\mu A } \wedge \gamma^\nu + I M } \wedge \delta A \\
&=
2 \lr{ - \grad \wedge (\partial_\nu A ) \wedge \gamma^\nu + I M } \wedge \delta A.
\end{aligned}
\end{equation}
We've dropped the complete derivative term, as the \( \delta A \) is zero on the boundary.   For the action variation to be zero, we require
\begin{equation}\label{eqn:fsquared:940}
\begin{aligned}
   0
   &= - \grad \wedge (\partial_\nu A ) \wedge \gamma^\nu + I M \\
   &= \grad \wedge \gamma^\nu \wedge (\partial_\nu A ) + I M \\
   &= \grad \wedge \lr{ \grad \wedge A } + I M \\
   &= \grad \wedge F + I M,
\end{aligned}
\end{equation}
or
\begin{equation}\label{eqn:fsquared:960}
   \grad \wedge F = -I M.
\end{equation}
Here we've had to dodge a sneaky detail, namely that \( \grad \wedge \lr{ \grad \wedge A } = 0 \), provided \( A \) has sufficient continuity that we can assert mixed partials.  We will see a way to resolve this contradiction when we vary a Lagrangian density that includes both electric and magnetic field contributions.

\section{Multivector Lagrangian for Maxwell's equation.}
We've found the charge and currency dependency parts of Maxwell's equations for both electric and magnetic sources, using scalar and pseudoscalar Lagrangian densities respectively.

Now comes the really cool part.  We can form a multivector Lagrangian and find Maxwell's equation in it's entirety in a single operation, without resorting to usual coordinate expansion of the fields.

Our Lagrangian is
\begin{equation}\label{eqn:fsquared:980}
   \LL = \inv{2} F^2 - \gpgrade{A \lr{ J - I M}}{0,4},
\end{equation}
where \( F = \grad \wedge A \).

The variation of the action formed from this Lagrangian density is
\begin{equation}\label{eqn:fsquared:1000}
   \delta S = \int d^4 x \lr{
      \inv{2} \lr{ F \delta F + (\delta F) F } - \gpgrade{ \delta A \lr{ J - I M} }{0,4}
   }.
\end{equation}
Both \( F \) and \( \delta F \) are STA bivectors, and for any two bivectors the symmetric sum of their products, selects the grade 0,4 components of the product.  That is, for bivectors, \( F, G \), we have
\begin{equation}\label{eqn:fsquared:1020}
   \inv{2}\lr{ F G + G F } = \gpgrade{F G}{0,4} = \gpgrade{G F}{0,4}.
\end{equation}
This means that the action variation integrand can all be placed into a 0,4 grade selection operation
\begin{equation}\label{eqn:fsquared:1040}
   \delta S
   = \int d^4 x \gpgrade{
      (\delta F) F - \delta A \lr{ J - I M}
   }{0,4}.
\end{equation}
Let's look at the \( (\delta F) F \) multivector in more detail
\begin{equation}\label{eqn:fsquared:1060}
\begin{aligned}
(\delta F) F
&=
\delta \lr{ \gamma^\mu \wedge \partial_\mu A } F \\
&=
\lr{ \gamma^\mu \wedge \delta \partial_\mu A } F \\
&=
   \lr{ \gamma^\mu \wedge \partial_\mu \delta A } F \\
&=
-
\lr{ (\partial_\mu \delta A) \wedge \gamma^\mu } F \\
&=
-
(\partial_\mu \delta A) \gamma^\mu F
-
\lr{ (\partial_\mu \delta A) \cdot \gamma^\mu } F
\\
\end{aligned}
\end{equation}
This second term is a bivector, so once filtered with a grade 0,4 selection operator, will be obliterated.
We are left with
\begin{equation}\label{eqn:fsquared:1080}
\begin{aligned}
   \delta S
   &= \int d^4 x \gpgrade{
-
(\partial_\mu \delta A) \gamma^\mu F
      - \delta A \lr{ J - I M}
   }{0,4}
   \\
   &= \int d^4 x \gpgrade{
-
\partial_\mu \lr{
\delta A \gamma^\mu F
}
+ \delta A \gamma^\mu \partial_\mu F
      - \delta A \lr{ J - I M}
   }{0,4}
   \\
   &= \int d^4 x
   \gpgrade{
      \delta A \lr{ \grad F - \lr{ J - I M} }
}{0,4}.
\end{aligned}
\end{equation}
As before, the total derivative term has been dropped, as variations \( \delta A \) are zero on the boundary.  The remaining integrand must be zero for all variations, so we conclude that
\begin{equation}\label{eqn:fsquared:1100}
   \boxed{
   \grad F = J - I M.
}
\end{equation}
Almost magically, out pops Maxwell's equation in it's full glory, with both four vector charge and current density, and also the trivector (fictitious) magnetic charge and current densities, should we want to include those.

\subsection{A final detail.}
There's one last thing to say.  If you have a nagging objection to me having declared that \( \grad F - \lr{ J - I M} = 0 \) when the whole integrand was enclosed in a grade 0,4 selection operator.  Shouldn't we have to account for the grade selection operator somehow?  Yes, we should, and I cheated a bit to not do so, but we get the same answer if we do.  To handle this with a bit more finesse, we split \( \grad F - \lr{ J - I M}  \) into it's vector and trivector components, and consider those separately
\begin{equation}\label{eqn:fsquared:1120}
\gpgrade{
      \delta A \lr{ \grad F - \lr{ J - I M} }
}{0,4}
=
\delta A \cdot \lr{ \grad \cdot F - J }
+
\delta A \wedge \lr{ \grad \wedge F + I M }.
\end{equation}
We require these to be zero for all variations \( \delta A \), which gives us two independent equations
\begin{equation}\label{eqn:fsquared:1140}
\begin{aligned}
   \grad \cdot F - J &= 0 \\
   \grad \wedge F + I M &= 0.
\end{aligned}
\end{equation}
However, we can now add up these equations, using \( \grad F = \grad \cdot F + \grad \wedge F \) to find, sure enough, that
\begin{equation}\label{eqn:fsquared:1160}
   \grad F = J - I M,
\end{equation}
as stated, somewhat sloppily, before.

\section{Progressing towards coordinate free form of the Euler-Lagrange equations.}
We managed to find Maxwell's equation in it's STA form by variation of a multivector Lagrangian, with respect to a four-vector field (the potential).  That approach differed from the usual variation with respect to the coordinates of that four-vector, or the use of the Euler-Lagrange equations with respect to those coordinates.

\subsection{Euler-Lagrange equations.}
Having done so, an immediate question is whether we can express the Euler-Lagrange equations with respect to the four-potential in it's entirety, instead of the coordinates of that vector.  I have some intuition about how to complete avoid that use of coordinates, but first we can get part way there.

Consider a general Lagrangian, dependent on a field \( A \) and all it's derivatives \( \partial_\mu A \)
\begin{equation}\label{eqn:fsquared:1180}
\LL = \LL( A, \partial_\mu A ).
\end{equation}

The variational principle requires
\begin{equation}\label{eqn:fsquared:1200}
   0 = \delta S = \int d^4 x \delta \LL( A, \partial_\mu A ).
\end{equation}
That variation can be expressed as a limiting parametric operation as follows
\begin{equation}\label{eqn:fsquared:1220}
   \delta S
   = \int d^4 x
   \lr{
   \lim_{t \rightarrow 0} \ddt{} \LL( A + t \delta A )
   +
   \sum_\mu
   \lim_{t \rightarrow 0} \ddt{} \LL( \partial_\mu A + t \delta \partial_\mu A )
   }
\end{equation}
We eventually want a coordinate free expression for the variation, but we'll use them to get there.  We can expand the first derivative by chain rule as
\begin{equation}\label{eqn:fsquared:1240}
\begin{aligned}
   \lim_{t \rightarrow 0} \ddt{} \LL( A + t \delta A )
   &=
   \lim_{t \rightarrow 0} \PD{(A^\alpha + t \delta A^\alpha)}{\LL} \PD{t}{}(A^\alpha + t \delta A^\alpha) \\
   &=
   \PD{A^\alpha}{\LL} \delta A^\alpha.
\end{aligned}
\end{equation}
This has the structure of a directional derivative \( A \).  In particular, let
\begin{equation}\label{eqn:fsquared:1260}
   \grad_A = \gamma^\alpha \PD{A^\alpha}{},
\end{equation}
so we have
\begin{equation}\label{eqn:fsquared:1280}
   \lim_{t \rightarrow 0} \ddt{} \LL( A + t \delta A )
   = \delta A \cdot \grad_A.
\end{equation}
Similarly,
\begin{equation}\label{eqn:fsquared:1300}
   \lim_{t \rightarrow 0} \ddt{} \LL( \partial_\mu A + t \delta \partial_\mu A )
   =
   \PD{(\partial_\mu A^\alpha)}{\LL} \delta \partial_\mu A^\alpha,
\end{equation}
so we can define a gradient with respect to each of the derivatives of \(A \) as
\begin{equation}\label{eqn:fsquared:1320}
   \grad_{\partial_\mu A} = \gamma^\alpha \PD{(\partial_\mu A^\alpha)}{}.
\end{equation}
Our variation can now be expressed in a somewhat coordinate free form
\begin{equation}\label{eqn:fsquared:1340}
   \delta S = \int d^4 x \lr{
      \lr{\delta A \cdot \grad_A} \LL + \lr{ \lr{\delta \partial_\mu A} \cdot \grad_{\partial_\mu A} } \LL
   }.
\end{equation}
We now sum implicitly over pairs of indexes \( \mu \) (i.e. we are treating \( \grad_{\partial_\mu A} \) as an upper index entity).  We can now proceed with our chain rule expansion
\begin{equation}\label{eqn:fsquared:1360}
\begin{aligned}
\delta S
&= \int d^4 x \lr{
      \lr{\delta A \cdot \grad_A} \LL + \lr{ \lr{\delta \partial_\mu A} \cdot \grad_{\partial_\mu A} } \LL
} \\
&= \int d^4 x \lr{
      \lr{\delta A \cdot \grad_A} \LL + \lr{ \lr{\partial_\mu \delta A} \cdot \grad_{\partial_\mu A} } \LL
} \\
&= \int d^4 x \lr{
\lr{\delta A \cdot \grad_A} \LL
+ \partial_\mu \lr{ \lr{ \delta A \cdot \grad_{\partial_\mu A} } \LL }
- \lr{\PD{x^\mu}{} \delta A \cdot \grad_{\partial_\mu A} \LL}_{\delta A}
}.
\end{aligned}
\end{equation}
As usual, we kill off the boundary term, by insisting that \( \delta A = 0 \) on the boundary, leaving us with a four-vector form of the field Euler-Lagrange equations
\begin{equation}\label{eqn:fsquared:1380}
\lr{\delta A \cdot \grad_A} \LL = \lr{\PD{x^\mu}{} \delta A \cdot \grad_{\partial_\mu A} \LL}_{\delta A},
\end{equation}
where the RHS derivatives are taken with \(\delta A \) held fixed.  We seek solutions of this equation that hold for all variations \( \delta A \).
\subsection{Application to the Maxwell Lagrangian.}
For the Maxwell application we need a few helper calculations.  The first, given a multivector \( B \), is
\begin{equation}\label{eqn:fsquared:1400}
\begin{aligned}
   \lr{ \delta A \cdot \grad_A } A B
&=
\delta A^\alpha \PD{A^\alpha}{} \gamma_\beta A^\beta B \\
&=
\delta A^\alpha \gamma_\alpha B \\
&=
\lr{ \delta A } B.
\end{aligned}
\end{equation}

Now let's compute, for multivector \( B \)
\begin{equation}\label{eqn:fsquared:1420}
\begin{aligned}
\lr{ \delta A \cdot \grad_{\partial_\mu A} } B F
&=
\delta A^\alpha \PD{(\partial_\mu A^\alpha)} B \lr{ \gamma^\beta \wedge \partial_\beta \lr{ \gamma_\pi A^\pi } } \\
&=
\delta A^\alpha B \lr{ \gamma^\mu \wedge \gamma_\alpha } \\
&=
B \lr{ \gamma^\mu \wedge \delta A }.
\end{aligned}
\end{equation}

Our Lagrangian is
\begin{equation}\label{eqn:fsquared:1440}
   \LL = \inv{2} F^2 - \gpgrade{A \lr{ J - I M } }{0,4},
\end{equation}
so
\begin{equation}\label{eqn:fsquared:1460}
\lr{\delta A \cdot \grad_A} \LL
=
-\gpgrade{ \lr{ \delta A } \lr{ J - I M } }{0,4},
\end{equation}
and
\begin{equation}\label{eqn:fsquared:1480}
\begin{aligned}
\lr{ \delta A \cdot \grad_{\partial_\mu A} } \inv{2} F^2
&=
\inv{2} \lr{ F \lr{ \gamma^\mu \wedge \delta A } + \lr{ \gamma^\mu \wedge \delta A } F } \\
&=
\gpgrade{
   \lr{ \gamma^\mu \wedge \delta A } F
}{0,4} \\
&=
-\gpgrade{
   \lr{ \delta A \wedge \gamma^\mu } F
}{0,4} \\
&=
-\gpgrade{
   \delta A \gamma^\mu  F
   -
   \lr{ \delta A \cdot \gamma^\mu } F
}{0,4} \\
&=
-\gpgrade{
   \delta A \gamma^\mu  F
}{0,4}.
\end{aligned}
\end{equation}
Taking derivatives (holding \( \delta A \) fixed), we have
\begin{equation}\label{eqn:fsquared:1500}
\begin{aligned}
-\gpgrade{ \lr{ \delta A } \lr{ J - I M } }{0,4}
&=
-\gpgrade{
   \delta A \partial_\mu \gamma^\mu F
}{0,4} \\
&=
-\gpgrade{
   \delta A \grad F
}{0,4}.
\end{aligned}
\end{equation}
We've already seen that the solution can be expressed without grade selection as
\begin{equation}\label{eqn:fsquared:1520}
   \grad F = \lr{ J - I M },
\end{equation}
which is Maxwell's equation in it's STA form.  It's not clear that this is really any less work, but it's a step towards a coordinate free evaluation of the Maxwell Lagrangian (at least not having to use the coordinates \( A^\mu \) as we have to do in the tensor formalism.)

\section{A coordinate free variation of the Maxwell equation multivector Lagrangian.}

For what is now (probably) the final step in this exploration, we now wish to evaluate the variation of the multivector Maxwell Lagrangian
\begin{equation}\label{eqn:fsquared:1440x}
   \LL = \inv{2} F^2 - \gpgrade{A \lr{ J - I M } }{0,4},
\end{equation}
without resorting to coordinate expansion of any part of \( F = \grad \wedge A \).  We'd initially evaluated this, expanding both \( \grad \) and \( A \) in coordinates, and then just \( \grad \), but we can avoid both.
In particular, given a coordinate free Lagrangian, and a coordinate free form of Maxwell's equation as the final destination, there must be a way to get there directly.

It is clear how to work through the first part of the action variation argument, without resorting to any sort of coordinate expansion
\begin{equation}\label{eqn:fsquared:1540}
\begin{aligned}
\delta S
&=
\int d^4 x \lr{ \inv{2} \lr{ \delta F } F + F \lr{ \delta F } } - \gpgrade{ \lr{ \delta F } \lr{ J - I M } }{0,4} \\
&=
\int d^4 x \gpgrade{ \lr{ \delta F } F - \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
\int d^4 x \gpgrade{ \lr{ \grad \wedge \lr{\delta A} } F - \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
-\int d^4 x \gpgrade{ \lr{ \lr{\delta A} \grad } F - \lr{ \lr{ \delta A } \cdot \grad } F + \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
-\int d^4 x \gpgrade{ \lr{ \lr{\delta A} \grad } F + \lr{ \delta A } \lr{ J - I M } }{0,4}.
\end{aligned}
\end{equation}

In the last three lines, it is important to note that \( \grad \) acts bidirectionally, on \( \delta A \), but not \( F \).
In particular, if \( B, C \) are multivectors, we interpret the bidirectional action of the gradient as
\begin{equation}\label{eqn:fsquared:1560}
\begin{aligned}
   B \lrgrad C &=
   B \gamma^\mu \lrpartial_\mu C \\
   &=
   (\partial_\mu B) \gamma^\mu C
   +
   B \gamma^\mu (\partial_\mu C),
\end{aligned}
\end{equation}
where the partial operators on the first line are bidirectionally acting, and braces have been used in the last line to indicate the scope of the operators in the chain rule expansion.

Let's also use arrows to clarify the directionality of this first part of the action variation, writing
\begin{equation}\label{eqn:fsquared:1580}
\begin{aligned}
\delta S
&=
-\int d^4 x \gpgrade{ \lr{\delta A} \lgrad F + \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
-\int d^4 x \gpgrade{ \lr{\delta A} \lrgrad F - \lr{\delta A} \rgrad F + \lr{ \delta A } \lr{ J - I M } }{0,4}.
\end{aligned}
\end{equation}
We can cast the first term into an integrand that can be evaluated using the Fundamental Theorem of Geometric Calculus, by introducing a
a parameterization \( x = x(a_\mu) \), for which the tangent space basis vectors are \( \Bx_{a_\mu} = \PDi{a_\mu}{x} \), and the pseudoscalar volume element is
\begin{equation}\label{eqn:fsquared:1640}
   d^4 \Bx = \lr{ \Bx_{a_0} \wedge \Bx_{a_1} \wedge \Bx_{a_2} \wedge \Bx_{a_3} } da_0 da_1 da_2 da_3 = I d^4 x.
\end{equation}
Writing \( d^4 x = -I d^4 \Bx \), we have
\begin{equation}\label{eqn:fsquared:1600}
\begin{aligned}
\delta S
&=
-\int_V d^4 x \gpgrade{ \lr{\delta A} \lrgrad F - \lr{\delta A} \rgrad F + \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
-\int_V \gpgrade{ -\lr{\delta A} I d^4 \Bx \lrgrad F - d^4 x \lr{\delta A} \rgrad F + d^4 x \lr{ \delta A } \lr{ J - I M } }{0,4} \\
&=
\int_{\partial V} \gpgrade{ \lr{\delta A} I d^3 \Bx F }{0,4}
+ \int_V d^4 x \gpgrade{ \lr{\delta A} \lr{ \rgrad F - J + I M } }{0,4}.
\end{aligned}
\end{equation}
The first integral is killed since \( \delta A = 0 \) on the boundary.  For the second integral to be zero for all variations \( \delta A \), we must have
\begin{equation}\label{eqn:fsquared:1660}
   \gpgrade{ \lr{\delta A} \lr{ \rgrad F - J + I M } }{0,4} = 0,
\end{equation}
but have argued previously that we can drop the grade selection, leaving
\begin{equation}\label{eqn:fsquared:1620}
   \boxed{
      \grad F = J - I M
   },
\end{equation}
where the directional indicator on our gradient has been dropped, since there is no longer any ambiguity.  This is Maxwell's equation in it's coordinate free STA form, found using the variational principle from a coordinate free multivector Maxwell Lagrangian, without having to resort to a coordinate expansion of that Lagrangian.

%}
%\EndArticle
\EndNoBibArticle
